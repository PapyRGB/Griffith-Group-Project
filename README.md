# ğŸ“ Griffith-Group-Project

> 3rd Year BSc (Hons) in Computing â€” Group Project  
> **Griffith College, Dublin** Â· BSCO-GP/Dub/FT Â· 2024â€“2025  
> Supervisor: Dr. Waseem Akhtar

This project implements a **Retrieval-Augmented Generation (RAG) assistant** tailored to Griffith College student documents. The assistant can ingest `.docx` and `.pdf` files (such as the official Student Handbook and Admin Info guide) and intelligently respond to user queries using LLMs, embeddings, and a custom-built retrieval pipeline.

---

## ğŸ—ï¸ Project Overview

- **Goal:** Assist Griffith College students by enabling natural language queries over static academic documents.
- **Input Sources:**  
  - `Admin Info.docx` â€“ internal faculty guidance  
  - `griffith-college-student-handbook-2024-25.pdf` â€“ official student guide
- **Approach:**  
  A streamlined RAG architecture using pre-trained models, embeddings, FAISS for retrieval, and Streamlit for interface.

---

## ğŸŒ¿ Branch Structure

| Branch                        | Purpose                                                             |
|------------------------------|---------------------------------------------------------------------|
| `main`                       | Stable, production-ready code                                       |
| `dev`                        | Active development integration                                      |
| `feature/docs_static_loader`| One-time ingestion of `.docx` and `.pdf` documents                  |
| `feature/embedding_faiss`    | Embedding generation and FAISS index creation                       |
| `feature/model_hf_api`       | Hugging Face Inference API integration                              |
| `feature/model_llama_local`  | Optional local LLM (`llama.cpp`) support                            |
| `feature/rag_retrieval`      | Retrieval logic to fetch relevant chunks based on queries           |
| `feature/streamlit_frontend` | Streamlit interface, caching decorators, and session management     |
| `feature/query_eval_testing` | Evaluation with sample queries, validation output, test harness     |
| `feature/deploy_config`      | Streamlit Cloud setup, environment vars, secrets, and deployment docs |

---

## ğŸ§± Stack Summary

| Layer             | Technology / Tool                                   | Purpose/Notes                                          |
|------------------|-----------------------------------------------------|--------------------------------------------------------|
| **Frontend**      | Streamlit                                           | UI for student queries                                 |
| **LLM**           | Hugging Face Inference API (Mistral-7B)            | Hosted model for production use                        |
|                  | `llama.cpp` (optional local use)                    | For demos or offline queries                           |
| **Embeddings**    | `BAAI/bge-small-en` (default)                      | Robust semantic embedding generation                   |
|                  | `all-MiniLM-L6-v2` (fallback)                       | Lightweight alternative                                |
| **Vector Store**  | FAISS                                               | Fast similarity search over document chunks            |
| **Caching**       | `@st.cache_data` (Streamlit)                       | Performance boost for repeat queries and startup       |
| **Storage**       | In-memory only                                     | No persistent user uploads supported                   |
| **Documents**     | `Admin Info.docx`, `griffith-college-student-handbook-2024-25.pdf` | Ingested once, read-only context                       |

---

## ğŸš€ Deployment

- **Production:** Streamlit Cloud with Hugging Face API (`mistralai/Mistral-7B-Instruct-v0.1`)
- **Local:** Optional `llama.cpp` with GGUF model support for offline use
- âš ï¸ Note: Streamlit Cloud does **not** support local binaries like `llama.cpp`

---

## âœ… Features

- ğŸ§  Question answering from Griffith documents
- ğŸ“„ Chunked ingestion and vectorized semantic search
- ğŸ” Fast FAISS-based document retrieval
- ğŸ§ª Sample query testing and evaluation scripts
- ğŸ“¦ Streamlit UI with dynamic session and caching
- ğŸ› ï¸ Ready for Streamlit Cloud deployment

---

## ğŸ“ Project Structure

```bash
Griffith-Group-Project/
â”œâ”€â”€ streamlit_app/             # Streamlit UI
â”œâ”€â”€ src/                          # RAG pipeline logic
â”‚   â”œâ”€â”€ document_loader.py        # PDF and DOCX ingestion
â”‚   â”œâ”€â”€ embed_index.py            # SentenceTransformer wrapper
â”‚   â”œâ”€â”€ hf_model.py               # HuggingFace and llama.cpp clients
â”‚   â””â”€â”€ retriever.py              # FAISS integration
â”œâ”€â”€ tests/                        # Pytest units testing 
â”‚   â”œâ”€â”€ model_evaluation/         # Model evaluation script
â”‚   â””â”€â”€ pytest/                   # Pytest unit testing   
â”œâ”€â”€ data/                         # Static documents and vector stores
â””â”€â”€ README.md
```

---

## ğŸ‘¥ Team Group 1

- [Maxime Viel](https://github.com/PapyRGB)
- [BenoÃ®t Catez](https://github.com/LimuleSempai)

---

## ğŸ“Œ References

- [Griffith College Student Handbook 2024â€“25](https://www.griffith.ie/)
- [Admin Info (Computing Faculty)](https://www.griffith.ie/faculties/computing-science)
- [Mistral-7B-Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
- [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en)
- [SentenceTransformers](https://www.sbert.net/)
- [FAISS](https://github.com/facebookresearch/faiss)
